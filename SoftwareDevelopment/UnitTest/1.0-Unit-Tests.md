###### [Home](https://github.com/RyKaj/Documentation/blob/master/README.md) | [Software Development](https://github.com/RyKaj/Documentation/tree/master/SoftwareDevelopment/README.md) | [Unit Test](https://github.com/RyKaj/Documentation/tree/master/SoftwareDevelopment/UnitTest/README.md) |
------------

# Information Technology : 1.0 Unit Tests


Unit Testing is defined as a type of software testing where individual
units/ components of a software are tested.

Unit Testing of software applications is done during the development
(coding) of an application. The objective of Unit Testing is to isolate
a section of code and verify its correctness. In procedural programming,
a unit may be an individual function or procedure. Unit Testing is
usually performed by the developer.

In SDLC, STLC, V Model, Unit testing is first level of testing done
before integration testing. Unit testing is a WhiteBox testing technique
that is usually performed by the developer. Though, in a practical world
due to time crunch or reluctance of developers to tests, QA engineers
also do unit testing.

People sometimes contrast the term "unit testing" with "integration
testing" or "end-to-end testing." The difference is that generally, unit
testing is done to validate the behavior of an individual testable unit,
whereas integration tests are validating the behavior of multiple
components together, or the application as a whole. Like I said, the
definition for what constitutes a "unit" is not strictly defined, and
it's up to you to decide the scope for each test.

<kbd>![Unit Testing](https://www.guru99.com/images/1/Unit-Testing.png)</kbd>
<kbd>![](attachments/451821274/463534091.jpg)</kbd>

## Why Unit Test?

Unit testing is a proven technique for ensuring software quality, with
plenty of benefits. Here are (more than) a few great reasons to unit
test:

  - Unit testing **validates**that each piece of your software not only
	works properly today, but continues to work in the future, providing
	a solid foundation for future development.
  - Unit testing **identifies defects at early stages** of the
	production process, which [reduces the
	costs](https://blog.parasoft.com/what-is-the-shift-left-approach-to-software-testing)
	of fixing them in later stages of the development cycle.
  - Unit-tested code is generally **safer to refactor**, since tests can
	be re-run quickly to validate that behavior has not changed.
  - Writing unit tests forces developers to consider how well the
	production code is designed in order to make it **suitable for unit
	testing**, and makes developers look at their code from a
	**different perspective**, encouraging them to consider corner cases
	and error conditions in their implementation.
  - Including unit tests in the **code review process** can reveal how
	the modified or new code is supposed to work. Plus, reviewers can
	confirm whether the tests are good ones or not.

It's unfortunate that all too often, developers either don't write unit
tests at all, don't write *enough* tests, or they don't *maintain* them.
I understand — unit tests can sometimes be tricky to write, or
time-consuming to maintain. Sometimes there's a deadline to meet, and it
feels like writing tests will make us miss that deadline. But not
writing enough unit tests or not writing good unit tests is a risky trap
to fall into.

So please consider my following best-practice recommendations on how to
write clean, maintainable, automated tests that give you all the
benefits of unit testing, with a minimum amount of time and effort.

## Less Tiem Performing Functional Tests

Functional tests are expensive. They typically involve opening up the
application and performing a series of steps that you (or someone else),
must follow in order to validate the expected behavior. These steps may
not always be known to the tester, which means they will have to reach
out to someone more knowledgeable in the area in order to carry out the
test. Testing itself could take seconds for trivial changes, or minutes
for larger changes. Lastly, this process must be repeated for every
change that you make in the system.

Unit tests, on the other hand, take milliseconds, can be run at the
press of a button and do not necessarily require any knowledge of the
system at large. Whether or not the test passes or fails is up to the
test runner, not the individual.

## Protection Against Regression

Regression defects are defects that are introduced when a change is made
to the application. It is common for testers to not only test their new
feature but also features that existed beforehand in order to verify
that previously implemented features still function as expected.

With unit testing, it's possible to rerun your entire suite of tests
after every build or even after you change a line of code. Giving you
confidence that your new code does not break existing functionality.

## Executable Documentation

It may not always be obvious what a particular method does or how it
behaves given a certain input. You may ask yourself: How does this
method behave if I pass it a blank string? Null?

When you have a suite of well-named unit tests, each test should be able
to clearly explain the expected output for a given input. In addition,
it should be able to verify that it actually works.

## Less Coupled Code

When code is tightly coupled, it can be difficult to unit test. Without
creating unit tests for the code that you're writing, coupling may be
less apparent.

Writing tests for your code will naturally decouple your code, because
it would be more difficult to test otherwise.

## Standards and Patterns

### Best Practices

Let's look at some best practices for building, running, and maintaining
unit tests, to achieve the best results.

  - Test cases should be small and isolated. As mentioned above, they
	should test something specific about the code.

  - Try keeping test to assertion ratio near to 1. It makes it easy to
	identify any assertion which has failed. Having multiple assertions
	can make it cumbersome to verify which assertion went rogue.

  - Always avoid test interdependence. Each test case should handle
	their own build up and tear down. Test runners don't generally run
	tests in any specified order. Thus, we can not assume anything based
	on the order in which we write the cases.

  - A test case approaches the behavioral aspect of the code. So it
	should be easily comprehensible in the sense that what we are
	testing and what to do in case of failure.

  - Mock as little as needed. Too many fakes create fragile tests which
	break when they code undergoes changes in production.

  - Avoid mocking chatty interfaces. Any change in the order of calling
	may break the test.

  - It should be independent of external factors. You must not require a
	setup to run a unit test.

  - We must maintain a clear naming convention in writing unit tests.
	This simply makes our code more comprehensible.

  - While working on a continuous integration build, always add the unit
	test cases to the build so that whenever one test case fails, the
	whole build fails thus leaving no exemptions.

  - **Fast**. It is not uncommon for mature projects to have thousands
	of unit tests. Unit tests should take very little time to run.
	Milliseconds.

  - **Isolated**. Unit tests are standalone, can be run in isolation,
	and have no dependencies on any outside factors such as a file
	system or database.

  - **Repeatable**. Running a unit test should be consistent with its
	results, that is, it always returns the same result if you do not
	change anything in between runs.

  - **Self-Checking**. The test should be able to automatically detect
	if it passed or failed without any human interaction.

  - **Timely**. A unit test should not take a disproportionately long
	time to write compared to the code being tested. If you find testing
	the code taking a large amount of time compared to writing the code,
	consider a design that is more testable.

#### Unit Tests Should Be Trustworthy

The test must fail if the code is broken and only if the code is broken.
If it doesn't, we cannot trust what the test results are telling us.

#### Unit Tests Should Be Maintainable and Readable

When production code changes, tests often need to be updated, and
possibly debugged as well. So it must be easy to read and understand the
test, not only for whoever wrote it, but for other developers as well.
Always organize and name your tests for clarity and readability.

#### Unit Tests Should Verify a Single-Use Case

Good tests validate one thing and one thing only, which means that
typically, they validate a single use-case. Tests that follow this best
practice are simpler and more understandable, and that is good for
maintainability and debugging. Tests that validate more than one thing
can easily become complex and time-consuming to maintain. Don't let this
happen.

Another best practice is to use a minimal number of assertions. Some
people recommend just one assertion per test (this may be a little too
restrictive); the idea is to focus on validating only what is needed for
the use-case you are testing.

#### Unit Tests Should Be Isolated

Tests should be runnable on any machine, in any order, without affecting
each other. If possible, tests should have no dependencies on
environmental factors or global/external state. Tests that have these
dependencies are harder to run and usually unstable, making them harder
to debug and fix, and end up costing more time than they save (see
**trustworthy**, above).

Martin Fowler, a few years ago, [wrote
about](https://www.martinfowler.com/bliki/UnitTest.html) "solitary" vs.
"sociable" code, to describe dependency usage in application code, and
how tests need to be designed accordingly. In his article, "solitary"
code doesn't depend on other units (it's more self-contained), whereas
"sociable" code does interact with other components. If the application
code is solitary, then the test is simple, but for sociable code under
test, you can either build a "solitary" or "sociable" test. A "sociable
test" would rely on real dependencies in order to validate behavior,
whereas a "solitary test" isolates the code under test from
dependencies. You can use mocks to isolate the code under test, and
build a "solitary" test for "sociable" code. We'll look at how to do
that below.

<kbd>![](https://blog.parasoft.com/hs-fs/hubfs/sociable%20vs%20solitary%20tests.png?width=424&name=sociable%20vs%20solitary%20tests.png)</kbd>

***Figure 1:**Sociable vs Solitary Tests. Source: Martin Fowler, 2014,
["Unit Test"](https://www.martinfowler.com/bliki/UnitTest.html)*

In general, using mocks for dependencies makes our life easier as
testers, because we can generate "solitary tests" for sociable code. A
sociable test for complex code may require a lot of setup, and may
violate the principles of being isolated and repeatable. But since the
mock is created and configured in the test, it is self-contained and we
have more control over the behavior of dependencies. Plus, we can test
more code paths. For instance, I can return custom values or throw
exceptions from the mock, in order to cover boundary or error
conditions.

#### Unit Tests Should Be Automated

Make sure tests are being run in an automated process. This can be
daily, or every hour, or in a Continuous Integration or Delivery
process. The reports need to be accessible to and reviewed by everyone
on the team. As a team, talk about which metrics you care about: code
coverage, modified code coverage, number of tests being run,
performance, etc.

A lot can be learned by looking at these numbers, and a big shift in
those numbers often indicates regressions that can be addressed
immediately.

#### Use a Good Mixture of Unit and Integration Tests

Michael Cohn's book, *[Succeeding with Agile: Software Development Using
Scrum](https://www.goodreads.com/book/show/6707987-succeeding-with-agile),*
addresses this using a testing pyramid model (see illustration in the
image below). This is a commonly-used model to describe the ideal
distribution of testing resources. The idea is that as you go up in the
pyramid, tests are usually more complex to build, more fragile, slower
to run, and slower to debug. Lower levels are more isolated and more
integrated, faster, and simpler to build and debug. Therefore, automated
unit tests should make up the bulk of your tests.

![](https://blog.parasoft.com/hs-fs/hubfs/pyramid.png?width=700&name=pyramid.png)

Unit tests should validate all of the details, the corner cases and
boundary conditions, etc. Component, integration, UI, and functional
tests should be used more sparingly, to validate the behavior of the
APIs or application as a whole. Manual tests should be a minimal
percentage of the overall pyramid structure, but are still useful for
release acceptance and exploratory testing. This model provides
organizations with a high level of automation and test coverage, so that
they can scale up their testing efforts and keep the costs associated
with building, running, and maintaining tests at a minimum.

#### Unit Tests Should Be Executed Within an Organized Test Practice

In order to drive the success of your testing at all levels, and make
the unit testing process scalable and sustainable, you will need some
additional practices in place. First of all, this means **writing unit
tests as you write your application code**. Some organizations write the
tests before the application code (
[test-driven](https://dzone.com/articles/why-developers-dont-use-tdd) or
[behavior-driven](https://dzone.com/articles/tddbdd-an-introduction-amp-usage-guide)
programming). The important thing is that tests go hand-in-hand with the
application code. The tests and application code should even be reviewed
together in the code review process. Reviews help you understand the
code being written (because they can see the expected behavior) and
improve tests too\!

Writing tests along with code isn't just for new behavior or planned
changes, it's critical for bug fixes too. **Every bug you fix should
have a test that verifies the bug is fixed**. This ensures that the bug
stays fixed in the future.

Adopt a zero-tolerance policy for failing tests. If your team is
ignoring test results, then why have tests at all? Test failures should
indicate real issues...so address those issues right away, before they
waste QA's time, or worse, they get into the released product.

The longer it takes to address failures, the more time and money those
failures will ultimately cost your organization. So run tests during
refactoring, run tests right before you commit code, and don't let a
task be considered "done" until the tests are passing too.

Finally, **maintain those tests**. As I said before, if you're not
keeping those tests up-to-date when the application changes, they lose
their value. Especially if they are failing, failing tests are costing
time and money to investigate each time they fail. Refactor the tests as
needed, when the code changes.

As you can see, maximizing your returns on money and time invested in
your unit tests requires some investment in applying best practices. But
in the end, the rewards are worth the initial investment.

### Anti-Patterns

  - Using nondeterministic factors in the codebase: Such scenarios are
	difficult to test especially when they don't reproduce/hold a
	constant value on each rerun. Eg Using Time as an authentication
	measure in code which would vary at each moment and also in
	different time zones.

  - Using side-effecting methods: Testing these could be as difficult as
	testing methods with a nondeterministic factor in them. Poorly
	designed untestable code introduce unwarranted complexities.

  - Impurity is highly toxic: Method depending upon nondeterministic or
	side-effecting methods themselves become the same kind and in the
	end complicate the entire codebase. Considering the effect it may
	have on a real-life complex application, we may find ourselves
	trapped in codebase filled with antipatterns, secret dependencies
	and all sorts of unpleasant scenarios.

  - Mocking interfaces and classes outside the codebase: If you don't
	fully understand the proper usage of an interface, you should avoid
	mocking it. Rather you should wrap interaction with external API
	classes into specially created interfaces for the same purpose.

  - Working with the mutable global state: Method depending upon mutable
	global state not only requires you to consider the current value but
	also be updated about other code that may have altered its value
	earlier. Hence its advisable to avoid them.

## Types of Unit Test

### Test-Driven Development (TDD)

A process for when you write and run your tests. Following it makes it
possible to have a very high test-coverage. Test-coverage refers to the
percentage of your code that is tested automatically, so a higher number
is better. TDD also reduces the likelihood of having bugs in your tests,
which can otherwise be difficult to track down.

The TDD process consists of the following steps:

  - Tests are written before the code
  - Rely heavily on testing frameworks
  - All classes in the applications are tested
  - Quick and easy integration is made possible

It can take some effort to learn well, but spending the time can pay off
big. TDD projects often get a code-coverage of 90-100%, which means
maintaining the code and adding new features is easy. This is because
you have a large set of tests, so you can trust your code and changes
work, and didn’t break any other code either.

<kbd>![](attachments/463529105.png)</kbd>

## Writing Efficient Code for your Unit Tests

### The First Principle

F.I.R.S.T principles for clean tests

  - **Fast:** The best tests are fast enough. If tests run slowly,
	you’ll probably be discouraged from running them frequently.
  - **Independent**: Always strive to avoid test interdependence. At no
	time should a test depend on the state of preceding tests. This
	allows you to run tests individually, which is great for debugging
	in the event of a test break.
  - **Repeatable:** Ideally, every test should be repeatable in
	different environments without being erroneous. If the tests do not
	rely on a database or network, then it should work in any
	environment as it only depends on the code to be tested. When such a
	test works in one environment and fails in another, then chances are
	the test or the method is set up wrongly.
  - **Self-validating:** Each test should have a single Boolean output-
	either a pass or a fail. You do not have to check through the log
	files to identify whether the test result was valid or not.
  - **Timely:** Unit tests should be created in a timely manner. In TDD,
	the ideal time for creating test code is before writing the
	production code.

### Each Test should have its own function

If you want to run multiple tests, for example, each test should have
its own function. This is where the one test-one function notion comes
into play. Consider the anatomy of this simple test:

<kbd>![](attachments/463530531.png)</kbd>

Lumping the two tests together is confusing because you’re not sure
whether the output from test one affects test two. Secondly, the
starting state of test two is not explicit. The test runs regardless of
the state test one finishes. There’s so much ambiguity to think about.
Now think of a situation where you lumped about 10 items in a single
test and something went wrong. It will be hard to identify which of the
10 items failed.

To fix this, we can set up two functions for each test as shown below

<kbd>![](attachments/463530532.png)</kbd>

In this test, we have an explicit starting state for test B. Notice how
this makes the tests easier to read and analyze.

## Myths and Facts
<table>
	<colgroup>
		<col style="width: 33%" />
		<col style="width: 66%" />
	</colgroup>
	<thead>
		<tr class="header">
			<th>Myths</th>
			<th>Facts</th>
		</tr>
	</thead>
	<tbody>
		<tr class="odd">
			<td>Test Driven Development Slows Teams Down</td>
			<td>
				<p>It’s true that when you first start using TDD, you’ll go slower than if you didn’t — but that’s only transactionally and temporarily true. Think of it this way; if I develop a feature in 1 hour, but spend 6 hours debugging it, that’s worse than spending 6 hours developing the feature through TDD, and 0 hours debugging it. Once that feature written through TDD gets to test; I am 
					<em>confident</em> in it. I’m not as confident (or really confident at all) that the tester won’t find an issue if I hadn’t built the tests first. After six hours of debugging, it’s quite likely I missed something, I’m too far into the weeds to realize it, but a fresh set of eyes (our friendly neighborhood QA) will likely find it.
				</p>
				<p>Babies crawl before they walk, and they walk before they run; but no one ever suggests babies should start out running — there’s too many fundamentals that get missed if you try that.</p>
				<p>Another reality is that we all take it for granted that ‘hardening’ and ‘bug fixing’ sprints occur; and they occur far too often, by necessity. What you may not realize is that 
					<em>that time counts against development too</em>. It’s an opportunity cost — if you have to spend entire sprints “hardening” or “bug fixing”, then you aren’t able to spend those sprints delivering features and value — you’re effectively shoring up the value you’ve already tried to create.
				</p>
				<p>Instead of doing that, why 
					<em>not</em> build the feature through TDD?
				</p>
			</td>
		</tr>
		<tr class="even">
			<td>Test driven Development is a Testing methodology</td>
			<td>
				<p>TDD is a 
					<em>development</em> methodology. It’s a way to develop software to achieve the following:
				</p>
				<ul>
					<li>Code that is designed to be testable</li>
					<li>Well understood code</li>
					<li>Well specified code</li>
					<li>easy to change code</li>
					<li>consistent and constant delivery</li>
				</ul>
				<p>The fact that there are tests is almost an accident of speech. When Test Driven Development was created, tests were the primary way to assert that behavior was a certain way; but we could have easily called it ‘example driven development’. TDD’s purpose is not to create tests; it’s to create code that’s easy to test and easy to change, and allow the creators to be confident 
					<em>when changing the code</em>.
				</p>
				<p>It is not a replacement for the normal QA process; and not a replacement for system based tests — 
					<em>though it can cut down drastically on the number of paths integration tests need to take to be useful</em>. This is especially true of the brand of TDD I teach: FauxO
					<br />
					<br />
Test Driven Development ensures teams of humans can work together to deliver better software, faster than if they hadn’t used TDD.
				</p>
			</td>
		</tr>
		<tr class="odd">
			<td>Unit Tests are a Development Methodology</td>
			<td>
				<p>Unit tests are a 
					<em>testing methodology,</em> not a 
					<em>development</em> methodology. The difference is subtle but important. You don’t create Unit tests to determine the path software ought to take; you create unit tests after the software is created to verify it does what you think it does — to double check your work.
				</p>
				<p>TDD, on the other hand, is a development methodology. it’s a way of developing software that puts the test first; and the implementation later. This allows you to specify the behavior you expect, before the behavior itself is written. Unit Testing takes the opposite approach; where the tests are written after the code.</p>
				<p>The reality is when you create the Unit Tests 
					<em>after</em> the code is written, the tests are more brittle and necessarily dependent upon all of the dependencies needed to run those tests.
				</p>
				<p>Unit Tests have their place — though I (and others) argue they should be shown the door in favor of good TDD practices and integration tests that don’t have to traverse every path through the application.</p>
			</td>
		</tr>
		<tr class="even">
			<td>Integration Tests + Unit Tests are Good Enough</td>
			<td>
				<p>If you develop code with unit tests and integration tests, you’ll run into two problems pretty often:</p>
				<ol>
					<li>Your Integration tests necessarily have to cover lots of different paths through the application if your application wasn’t developed through TDD. This is untenable. JB Rainsberger famously said 
						<a href="https://www.youtube.com/watch?v=VDfX44fZoMc">Integration Tests are a Scam</a> , and it’s partly because of how we write code.
					</li>
					<li>Your Unit tests (again, without developing them through TDD), are bound to the implementation and dealing with all the dependencies you created because the pain of adding a dependency wasn’t apparent until you tried to write unit tests after the fact. That means if your implementation changes or your caller changes, your test could very well fail, even though nothing of substance changed. A common smell that this is the case is extensive use of Mocks and Stubs.</li>
				</ol>
				<p>In reality, Integration Tests + Unit tests are treated as good enough, when together, they’re about the most painful way you can test and develop software. (I believe in Integration tests — but they should be spared from having to go through the thousands of codepaths – that should be able to be handled through code that’s been developed through TDD.</p>
			</td>
		</tr>
		<tr class="odd">
			<td>The Goal of TDD is 100% test coverage</td>
			<td>
				<p>This is another one of those instances where ‘test’ was an unfortunate characterization for TDD. If some TDD is good, and more is better, why not go with the most TDD? 100%?</p>
				<p>Besides being infeasible (Frameworks and the icky-real world structures like the Network, Disk, Databases and the system clock get in the way), there is a point of diminishing returns; and those returns hit right about the time you try to deal with the Network, Disk, Databases, and the System Clock in an extensive fashion. This is why “Outside-In” TDD comes across as a brittle to change -&gt; The Mocks and Stubs replace real-world implementations; and we frequently find ourselves wanting to change those implementations.</p>
				<p>Also, since TDD is a development methodology, it’s not trying to be a testing methodology — that’s a useful by-product of TDD, but it isn’t 
					<em>the goal</em>. The goal is code that is built to be easily changeable, well-understood, and its behavior specified.
				</p>
			</td>
		</tr>
		<tr class="even">
			<td>You should aspire for 100% test coverage</td>
			<td>The reality is if you work with very expensive equipment, the value of 100% test coverage outweighs its cost. If your software deals with safety or security, that’s also true. If you’re writing a banking back-end — that is very likely true; but for the rest of us; you want enough test-coverage that you’re confident in making changes; but not so much that the tests get in your way of making change (again, brittle tests make code hard to change).</td>
		</tr>
	</tbody>
</table>

### Behavior-Driven Development (BBD)

Is a set of best practices for writing great tests. BDD can, and should
be, used together with TDD and unit testing methods.

One of the key things BDD addresses is implementation detail in unit
tests. A common problem with poor unit tests is they rely too much on
how the tested function is implemented. This means if you update the
function, even without changing the inputs and outputs, you must also
update the test. This is a problem because it makes doing changes
tedious.

Behavior-Driven Development addresses this problem by showing you how to
test. You should not test implementation, but instead behavior.

## Code Coverage and Test Coverage

### Code Coverage vs. Test Coverage

*Test coverage* and *code coverage* are often used interchangeably, but
they mean very different things:

  - **Code coverage** is a metric showing the proportion of *code* covered by tests
  - **Test coverage** is about the proportion of a *story or feature* covered by tests

Opinions on which is “better” do vary, but — shocking disclosure alert —
I’m a great fan of test coverage and not so keen on code coverage (at
least, when used as a stick to hit developers with). They both have
their uses though.

#### Code Coverage

In general, code coverage is a measurement of how much of the production
code is executed while your automated tests are running. By running a
suite of tests and looking at code coverage data, you can get a general
sense of how much of your application is being tested.

There are many kinds of code coverage — the most common ones are line
coverage and branch coverage. Most tools focus on line coverage, which
just tells you if a specific line was covered. Branch is more granular,
as it tells you if *each path through the code* is covered.

Code coverage is an important metric, but remember that increasing it is
a means to an end. It's great for finding gaps in testing, but it's not
the only thing to focus on. Be careful not to spend too much effort
trying to achieve 100% coverage — it may not even be possible or
feasible, and really the quality of your tests is the important thing.
That being said, achieving at least 60% coverage for your projects is a
good starting point, and 80% or more is a good goal to set. Obviously,
it's up to you to decide what that goal should be.

> This type of analysis is  ***statement coverage*** . Many such tools
> also analyze ***branch coverage*** , i.e. given a branching condition
> in the code, are all the evaluated possibilities reached by a test?

It's also valuable if you have automated tools that not only measure
code coverage but also keep track how much modified code is being
covered by tests, because this can provide visibility into whether
enough tests are being written along with changes in production code.

See here an example code coverage report:

<kbd>![](https://blog.parasoft.com/hs-fs/hubfs/Blogs/Two%20Big%20Traps%20of%20Code%20Coverage%20Image%202.png?width=1211&name=Two%20Big%20Traps%20of%20Code%20Coverage%20Image%202.png)</kbd>

Another thing to keep in mind is that, when writing new tests, be
careful of focusing on line coverage alone, as single lines of code can
result in multiple code paths, so make sure your tests validate these
code paths. Line coverage is a useful quick indicator, but it isn't the
only thing to look for.

The most obvious way to increase coverage is simply to add more tests
for more code paths, and more use-cases of the method under test. A
powerful way to increase coverage is to use parameterized tests.

Ironically,  **none of these tests verified the result** — they simply
called the functions. Yet that still counts as 100% coverage.

The idea of code coverage stems from the principle that no code should
enter production without some sort of test.

That might seem extreme if all your tests are “up close” white-box unit
tests. But if you zoom out a tad and write [component
tests](https://medium.com/@SoftwareReality/unit-tests-vs-component-tests-size-isnt-everything-eaded162c595)
instead, then more code can be covered by a single test. This makes high
levels of coverage more achievable:

<kbd>![](https://miro.medium.com/max/4255/1*yH1k3UAyaJ1bDYXkQh1dWA.jpeg)</kbd>

In the above diagram, the component test is focused on function `a`’s
interface and its output, while the unit tests are likely more focused
on the inner workings of `b` and `c`. They’re more zoomed-in, testing
lines of code in finer detail.

Both cases “cover the code with tests”, but in different ways and with
different emphases. The tests aren’t equal, so one “coverage score”
doesn’t make sense.

Another issue is that the project’s code coverage metric can easily be
increased by writing a
[zero-assertion](https://stackoverflow.com/questions/137399/unit-testing-without-assertions)
test case like the example at the start of this article.

  - An assertion-free test is like a tourist on an open-top bus, riding
	past the code at high speed, more concerned with his thermos of hot
	chocolate than with the sights whizzing past.
  - A test that does its job is more like a building inspector, checking
	each tourist attraction meticulously to verify that it isn’t about
	to fall down.

In other words…

> There’s code coverage and then there’s ***CODE COVERAGE***

So an overall percentage score is almost certainly misleading.

#### Why Use Code Coverage

Here, are some prime reasons for using code coverage:

  - It helps you to measure the efficiency of test implementation
  - It offers a quantitative measurement.
  - It defines the degree to which the source code has been tested.

#### Code Coverage Methods

##### Statement Coverage

What is Statement Coverage?

Statement coverage is a white box test design technique which involves
execution of all the executable statements in the source code at least
once. It is used to calculate and measure the number of statements in
the source code which can be executed given the requirements.

Statement coverage is used to derive scenario based upon the structure
of the code under test.

<kbd>![](https://www.guru99.com/images/jsp/030116_0814_LearnStatem1.png)</kbd>

In [White Box Testing](https://www.guru99.com/white-box-testing.html),
the tester is concentrating on how the software works. In other words,
the tester will be concentrating on the internal working of source code
concerning control flow graphs or flow charts.

Generally in any software, if we look at the source code, there will be
a wide variety of elements like operators, functions, looping,
exceptional handlers, etc. Based on the input to the program, some of
the code statements may not be executed. The goal of Statement coverage
is to cover all the possible path's, line, and statement in the code.

Let's understand this with an example, how to calculate statement
coverage.

Scenario to calculate Statement Coverage for given source code. Here we
are taking two different scenarios to check the percentage of statement
coverage for each scenario.

**Example**

##### Source Code

>     Prints (int a, int b) {                       ------------  Printsum is a function 
>         int result = a+ b; 
>         If (result> 0)
>             Print ("Positive", result)
>         Else
>             Print ("Negative", result)
>         }

##### Scenario 1

If A = 3, B = 9

<kbd>![](https://www.guru99.com/images/1/102518_1122_CodeCoverag2.png)</kbd>

The statements marked in yellow color are those which are executed as
per the scenario

Number of executed statements = 5, Total number of statements = 7

Statement Coverage: 5/7 = 71%

<kbd>![](https://www.guru99.com/images/jsp/030116_0814_LearnStatem2.png)</kbd>

##### Scenario 2

If A = -3, B = -9

<kbd>![](https://www.guru99.com/images/1/102518_1122_CodeCoverag4.png)</kbd>

The statements marked in yellow color are those which are executed as
per the scenario.

Number of executed statements = 6

Total number of statements = 7

<kbd>![](https://www.guru99.com/images/jsp/030116_0814_LearnStatem6.png)</kbd>

Statement Coverage: 6/7 = 85%

<kbd>![](https://www.guru99.com/images/jsp/030116_0814_LearnStatem3.png)</kbd>

But overall if you see, all the statements are being covered by 2
<sup>nd</sup> scenario's considered. So we can conclude that overall
statement coverage is 100%.

<kbd>![](https://www.guru99.com/images/jsp/030116_0814_LearnStatem4.png)</kbd>

#### Decision Coverage

Decision coverage reports the true or false outcomes of each Boolean
expression. In this coverage, expressions can sometimes get complicated.
Therefore, it is very hard to achieve 100% coverage.

That's why there are many different methods of reporting this metric.
All these methods focus on covering the most important combinations. It
is very much similar to decision coverage, but it offers better
sensitivity to control flow.

<kbd>![](https://www.guru99.com/images/1/102518_1122_CodeCoverag12.jpg)</kbd>

**Example**

##### Source Code

> 
> 
>     Demo(int a) {
>          If (a> 5)
>             a=a*3
>          Print (a)
>         }

###### Scenario 1

Value of a is 2

<kbd>![](https://www.guru99.com/images/1/102518_1122_CodeCoverag8.png)</kbd>

The code highlighted in yellow will be executed. Here the "No" outcome
of the decision If (a\>5) is checked.

Decision Coverage = 50%

###### Scenario 2

Value of a is 6

<kbd>![](https://www.guru99.com/images/1/102518_1122_CodeCoverag9.png)</kbd>

The code highlighted in yellow will be executed. Here the "Yes" outcome
of the decision If (a\>5) is checked.

Decision Coverage = 50%

<table>
	<thead>
		<tr>
			<th>Test Case</th>
			<th>Value of A</th>
			<th>Output</th>
			<th>Decision Coverage</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>1</td>
			<td>2</td>
			<td>2</td>
			<td>50%</td>
		</tr>
		<tr>
			<td>2</td>
			<td>6</td>
			<td>18</td>
			<td>50%</td>
		</tr>
	</tbody>
</table>


#### Branch Coverage

In the branch coverage, every outcome from a code module is tested. For
example, if the outcomes are binary, you need to test both True and
False outcomes.

It helps you to ensure that every possible branch from each decision
condition is executed at least a single time.

By using Branch coverage method, you can also measure the fraction of
independent code segments. It also helps you to find out which is
sections of code don't have any branches.

The formula to calculate Branch Coverage:

<kbd>![](https://www.guru99.com/images/1/102518_1122_CodeCoverag13.jpg)</kbd>

**Example**

##### Source Code

>     Demo(int a) {
>          If (a> 5)
>             a=a*3
>          Print (a)
>         }

<kbd>![](https://www.guru99.com/images/1/102518_1122_CodeCoverag10.png)</kbd>

Branch Coverage will consider unconditional branch as well

<table>
	<thead>
		<tr>
			<th>Test Case</th>
			<th>Value of A</th>
			<th>Output</th>
			<th>Decision Coverage</th>
			<th>Branch Coverage</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>1</td>
			<td>2</td>
			<td>2</td>
			<td>50%</td>
			<td>
				<strong>33%</strong>
			</td>
		</tr>
		<tr>
			<td>2</td>
			<td>6</td>
			<td>18</td>
			<td>50%</td>
			<td>
				<strong>67%</strong>
			</td>
		</tr>
	</tbody>
</table>


##### Advantages of Branch coverage:

Branch coverage Testing offers the following advantages:

  - Allows you to validate-all the branches in the code
  - Helps you to ensure that no branched lead to any abnormality of the
	program's operation
  - Branch coverage method removes issues which happen because of
	statement coverage testing
  - Allows you to find those areas which are not tested by other testing
	methods
  - It allows you to find a quantitative measure of code coverage
  - Branch coverage ignores branches inside the Boolean expressions

#### Condition Coverage

Conditional coverage or expression coverage will reveal how the
variables or sub expressions in the conditional statement are evaluated.
In this coverage expressions with logical operands are only considered.

For example, if an expression has Boolean operations like AND, OR, XOR,
which indicated total possibilities.

Conditional coverage offers better sensitivity to the control flow than
decision coverage. Condition coverage does not give a guarantee about
full decision coverage

The formula to calculate Condition Coverage:

<kbd>![](https://www.guru99.com/images/1/102518_1122_CodeCoverag14.jpg)</kbd>

**Example**

<kbd>![](https://www.guru99.com/images/1/102518_1122_CodeCoverag11.png)</kbd>

For the above expression, we have 4 possible combinations

  - TT
  - FF
  - TF
  - FT

Consider the following input

X=3

Y=4

(x\<y)

TRUE

Condition Coverage is ¼ = 25%

A=3

B=4

(a\>b)

FALSE

#### Finite State Machine (FSM) Coverage

Finite state machine coverage is certainly the most complex type of code
coverage method. This is because it works on the behavior of the design.
In this coverage method, you need to look for how many time-specific
states are visited, transited. It also checks how many sequences are
included in a finite state machine.

\<32 id="id-1.0UnitTests-WhichTypeofCodeCoveragetoChoose"\>Which Type of
Code Coverage to Choose

This is certainly the most difficult answer to give. In order to select
a coverage method, the tester needs to check that the

  - code under test has single or multiple undiscovered defects
  - cost of the potential penalty
  - cost of lost reputation
  - cost of lost sale, etc.

The higher the probability that defects will cause costly production
failures, the more severe the level of coverage you need to choose.

### Code Coverage vs. Functional Coverage

<thead>
	<tr>
		<th>
			<strong>Code Coverage</strong>
		</th>
		<th>
			<strong>Functional Coverage</strong>
		</th>
	</tr>
</thead>
<tbody>
	<tr>
		<td>Code coverage tells you how well the source code has been exercised by your test bench.</td>
		<td>Functional coverage measures how well the functionality of the design has been covered by your test bench.</td>
	</tr>
	<tr>
		<td>Never use a design specification</td>
		<td>Use design specification</td>
	</tr>
	<tr>
		<td>Done by developers</td>
		<td>Done by Testers</td>
	</tr>
</tbody>undefined</table>


### Advantages of Using Code Coverage

  - Helpful to evaluate a quantitative measure of code coverage
  - It allows you to create extra test cases to increase coverage
  - It allows you to find the areas of a program which is not exercised
	by a set of test cases

### Disadvantages of Using Code Coverage

  - Even when any specific feature is not implemented in design, code
	coverage still report 100% coverage.
  - It is not possible to determine whether we tested all possible
	values of a feature with the help of code coverage
  - Code coverage is also not telling how much and how well you have
	covered your logic
  - In the case when the specified function hasn't implemented, or a not
	included from the specification, then structure-based techniques
	cannot find that issue.

## Test Coverage

> **Side note:** Normally I use the name ***requirements coverage*** ,
> as it’s more akin to what the metric actually represents. But for
> consistency I’ll keep going with *test coverage* for this article.

A quick reminder:

> **Test coverage** is about the proportion of a story or feature covered by tests.

Conversations about test coverage tend to center around [acceptance
tests](https://medium.com/swlh/write-tests-at-three-levels-909561a9544b),
which follow the requirements more naturally than code-centric,
developer-owned tests (unit tests, component tests). Use a BDD framework
such as [Serenity](http://www.thucydides.info/#/whatisserenity) (wisely
renamed from Thucydides) to report on which requirements have acceptance
tests, and “pow”, you have your test coverage score. Pretty
straightforward\!

That’s all fine, but there’s much to be gained from viewing your
developer-owned tests in terms of test coverage as well.

This approach is *infinitely* more useful than code coverage (yes, that
much\!) because:

  - It encourages developers to focus their tests on the business domain
	and the requirements (stories and scenarios), with the result that…
  - Your tests will become more purposeful. And…
  - Because you’re writing a test for each scenario, you know when
	you’ve written enough tests — and *ipso facto* when you’ve written
	enough code overall.

While you’re measuring test coverage, it’s still useful to run a code
coverage tool to discover areas of code that aren’t tested at all — even
though it’s really quite a narrow metric.

But instead of asking “Why isn’t this code covered by tests?” try asking
instead:

> “Why is this code here at all?”

If the code doesn’t have any tests, that means it likely isn’t covered
by any particular story… so no-one asked for it… which means it isn’t
providing business value… which means it can probably even be deleted.

This is why the *code coverage* score is still useful. It isn’t the “80%
covered” score that you’re interested in, it’s the other side — the “20%
missed”:

<kbd>![](https://miro.medium.com/max/3382/1*UI9iCUrRPiGos7kEVqxbVA.jpeg)</kbd>

Code **un**coverage?

So the code coverage metric can be used to indicate where there might be
insufficient test coverage — or code that can potentially be deleted.

But we just used a code coverage tool to uncover missing test coverage.
Why not use a test coverage tool instead?

There are some around, generally built into BDD frameworks such as
[Robot Framework](https://robotframework.org/) and the imaginatively
named [Test Project](https://testproject.io/).

But these have the same kind-of unavoidable problem that test coverage
does—they don’t tell you the quality of your coverage. Taken to
extremes, your tests could consist of `assert 1 == 1` and get a 100%
score.

And, more pertinently, these test frameworks don’t extend beyond BDD
into the lower-level, developer-owned tests.

But that’s actually ok. As you’ve seen,

> code/test coverage scores just don’t bring home the bacon.

Really, **test coverage is more of a concept than a measurable score**.
Yet the effect of not having requirements-based tests in your project
*is* measurable, in the number of bugs that’ll surface in production.

###### References

  - [Codeburst - code coverage vs test coverage](https://codeburst.io/code-coverage-vs-test-coverage-c9afb261e902)
  - [DZone - Unit testing best practices how to get the most out](https://dzone.com/articles/unit-testing-best-practices-how-to-get-the-most-ou)
  - [DZone - why developers dont use tdd](https://dzone.com/articles/why-developers-dont-use-tdd)
  - [DZone tddbdd an introduction amp usage guide](https://dzone.com/articles/tddbdd-an-introduction-amp-usage-guide)<https://docs.microsoft.com/en-us/dotnet/core/testing/unit-testing-best-practices>
  - [MS Doc - unit testing best practices](https://docs.microsoft.com/en-us/dotnet/core/testing/unit-testing-best-practices)
  - [Code Utopia - unit testing tdd and bdd](https://codeutopia.net/blog/2015/03/01/unit-testing-tdd-and-bdd/)
  - [Guru99 - unit testing guide](https://www.guru99.com/unit-testing-guide.html)
  - [Guru99 - code coverage](https://www.guru99.com/code-coverage.html)
  - [Codeburst - code coverage vs test coverage](https://codeburst.io/code-coverage-vs-test-coverage-c9afb261e902)
  - [Osherove - Art of unit testing](https://osherove.com/blog/2019/11/12/an-updated-diagram-of-the-tdd-process-from-the-upcoming-3rd-edition-of-art-of-unit-testing)
  - [Medium Justin Parsons - writing efficient code for your unit tests](https://medium.com/@Justin_Parsons/writing-efficient-code-for-your-unit-tests-64a592efc410)
  - [Georgestocker - myths and facts about tdd unit testing and team velocity](https://georgestocker.com/2020/03/17/myths-and-facts-about-tdd-unit-testing-and-team-velocity/?utm_source=rss&utm_medium=rss&utm_campaign=myths-and-facts-about-tdd-unit-testing-and-team-velocity)


